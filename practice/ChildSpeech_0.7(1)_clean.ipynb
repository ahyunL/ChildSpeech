{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "machine_shape": "hm",
   "gpuType": "T4",
   "authorship_tag": "ABX9TyNx0tOECfFjiyWopjfulcAG"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TqFg51t0MRIy",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1762794128376,
     "user_tz": -540,
     "elapsed": 6974,
     "user": {
      "displayName": "ì´ì•„í˜„",
      "userId": "10263290526675293811"
     }
    },
    "outputId": "11a6da1e-580b-422b-ae82-c9789a5ae32e"
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers datasets soundfile torchaudio jiwer accelerate evaluate"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install -q torch torchaudio torchcodec datasets==3.0.0 transformers==4.44.0"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GD90X7wkk5kC",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1762794143454,
     "user_tz": -540,
     "elapsed": 15071,
     "user": {
      "displayName": "ì´ì•„í˜„",
      "userId": "10263290526675293811"
     }
    },
    "outputId": "de89ad76-2ac6-4c1b-937a-e7e70450650b"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CvByOvyiR0yq",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1762794162725,
     "user_tz": -540,
     "elapsed": 19254,
     "user": {
      "displayName": "ì´ì•„í˜„",
      "userId": "10263290526675293811"
     }
    },
    "outputId": "3e600821-9273-4560-c08c-f38105637598"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import subprocess\n",
    "from typing import List\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from datasets import Dataset, Audio\n",
    "from transformers import (\n",
    "    WhisperProcessor,\n",
    "    WhisperForConditionalGeneration,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "import evaluate\n",
    "\n",
    "# ---------------------------------------------------\n",
    "#  ê²½ë¡œ ì„¤ì •\n",
    "# ---------------------------------------------------\n",
    "ROOT_DIR   = \"/content/drive/MyDrive/childrenvoice\"\n",
    "\n",
    "TRAIN_BASE = os.path.join(ROOT_DIR, \"trainingdata\", \"Sourcedata\")\n",
    "VAL_BASE   = os.path.join(ROOT_DIR, \"valdata\")\n",
    "TEST_BASE  = os.path.join(ROOT_DIR, \"testdata\")\n",
    "LABEL_BASE = os.path.join(ROOT_DIR, \"trainingdata\", \"labellingdata\")\n",
    "\n",
    "TARGET_AGES = [4, 5, 6, 7]\n",
    "\n",
    "print(\"ROOT_DIR  :\", ROOT_DIR)\n",
    "print(\"TRAIN_BASE:\", TRAIN_BASE)\n",
    "print(\"VAL_BASE  :\", VAL_BASE)\n",
    "print(\"TEST_BASE :\", TEST_BASE)\n",
    "print(\"LABEL_BASE:\", LABEL_BASE)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "#  JSON â†’ í…ìŠ¤íŠ¸ ì¶”ì¶œ í•¨ìˆ˜\n",
    "#  (ë„¤ê°€ ì“°ë˜ extract_text_from_json ê·¸ëŒ€ë¡œ)\n",
    "# ---------------------------------------------------\n",
    "def extract_text_from_json(data):\n",
    "    \"\"\"\n",
    "    AI-Hub ì•„ë™ ìŒì„± ë¼ë²¨ êµ¬ì¡°ì— ë§ì¶°ì„œ\n",
    "    Transcription -> LabelText ê°’ì„ ìš°ì„ ì ìœ¼ë¡œ êº¼ë‚¸ë‹¤.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        text = data[\"Transcription\"][\"LabelText\"]\n",
    "        if isinstance(text, str):\n",
    "            return text.strip()\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "    # í˜¹ì‹œ êµ¬ì¡°ê°€ ë‹¤ë¥¼ ê²½ìš° ì „ì²´ì—ì„œ ë¬¸ìì—´ ê¸ì–´ì˜¤ê¸°\n",
    "    def collect_all_strings(obj, bucket):\n",
    "        if isinstance(obj, dict):\n",
    "            for v in obj.values():\n",
    "                collect_all_strings(v, bucket)\n",
    "        elif isinstance(obj, list):\n",
    "            for item in obj:\n",
    "                collect_all_strings(item, bucket)\n",
    "        elif isinstance(obj, str):\n",
    "            s = obj.strip()\n",
    "            if s:\n",
    "                bucket.append(s)\n",
    "\n",
    "    strings = []\n",
    "    collect_all_strings(data, strings)\n",
    "\n",
    "    if not strings:\n",
    "        return None\n",
    "\n",
    "    strings.sort(key=len, reverse=True)\n",
    "    return strings[0]\n",
    "\n",
    "# ---------------------------------------------------\n",
    "#  splitë³„ (train/val/test) ê¸°ë³¸ rows ë§Œë“¤ê¸°\n",
    "#  (wav ê²½ë¡œë§Œ, textëŠ” ë¹ˆ ë¬¸ìì—´)\n",
    "# ---------------------------------------------------\n",
    "def build_base_df(split_name: str, base_dir: str, target_ages: List[int]) -> pd.DataFrame:\n",
    "    rows = []\n",
    "\n",
    "    for age in target_ages:\n",
    "        age_dir = os.path.join(base_dir, f\"age{age}\")\n",
    "        if not os.path.isdir(age_dir):\n",
    "            print(f\"âš ï¸ {split_name}: age{age} í´ë” ì—†ìŒ: {age_dir}\")\n",
    "            continue\n",
    "\n",
    "        for speaker_id in sorted(os.listdir(age_dir)):\n",
    "            spk_dir = os.path.join(age_dir, speaker_id)\n",
    "            if not os.path.isdir(spk_dir):\n",
    "                continue\n",
    "\n",
    "            wav_files = sorted(glob.glob(os.path.join(spk_dir, \"*.wav\")))\n",
    "            if not wav_files:\n",
    "                print(f\"âš ï¸ {split_name}: wav ì—†ìŒ: {spk_dir}\")\n",
    "                continue\n",
    "\n",
    "            for wav_path in wav_files:\n",
    "                basename = os.path.basename(wav_path)      # K0001...\n",
    "                utt_id   = os.path.splitext(basename)[0]   # í™•ì¥ì ì œê±°\n",
    "\n",
    "                rows.append({\n",
    "                    \"split\": split_name,\n",
    "                    \"age\": age,\n",
    "                    \"speaker_id\": speaker_id,\n",
    "                    \"utt_id\": utt_id,\n",
    "                    \"audio_path\": wav_path,\n",
    "                    \"text\": \"\",     # ë‚˜ì¤‘ì— ì±„ì›€\n",
    "                    \"speed\": 1.0,\n",
    "                    \"is_augmented\": False,\n",
    "                })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    print(f\"\\nâœ… {split_name} base df ìƒ˜í”Œ ìˆ˜:\", len(df))\n",
    "    if len(df) > 0:\n",
    "        print(\"   ì˜ˆì‹œ:\")\n",
    "        display(df.head())\n",
    "    return df\n",
    "\n",
    "train_base_df = build_base_df(\"train\", TRAIN_BASE, TARGET_AGES)\n",
    "val_base_df   = build_base_df(\"val\",   VAL_BASE,   TARGET_AGES)\n",
    "test_base_df  = build_base_df(\"test\",  TEST_BASE,  TARGET_AGES)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "#  LABEL_BASE / speaker_id / utt_id.json ì—ì„œ í…ìŠ¤íŠ¸ ë¶™ì´ê¸°\n",
    "#  (ì œë¡œìƒ· ë•Œ ì“°ë˜ ë°©ì‹ ê·¸ëŒ€ë¡œ í™•ì¥)\n",
    "# ---------------------------------------------------\n",
    "def attach_labels(df: pd.DataFrame, label_base: str) -> pd.DataFrame:\n",
    "    utt2text = {}\n",
    "    not_found_json = 0\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        spk = row[\"speaker_id\"]   # ì˜ˆ: \"0282\"\n",
    "        utt = row[\"utt_id\"]       # ì˜ˆ: \"K0001...\"\n",
    "\n",
    "        json_path = os.path.join(label_base, spk, utt + \".json\")\n",
    "\n",
    "        if not os.path.exists(json_path):\n",
    "            not_found_json += 1\n",
    "            continue\n",
    "\n",
    "        with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            try:\n",
    "                data = json.load(f)\n",
    "            except Exception as e:\n",
    "                print(\"âš ï¸ JSON ë¡œë“œ ì‹¤íŒ¨:\", json_path, \"ì—ëŸ¬:\", e)\n",
    "                continue\n",
    "\n",
    "        text = extract_text_from_json(data)\n",
    "        if text:\n",
    "            utt2text[utt] = text\n",
    "\n",
    "    print(\"âœ… jsonì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜¨ utt ê°œìˆ˜:\", len(utt2text))\n",
    "    print(\"âš ï¸ json íŒŒì¼ì´ ì—†ì–´ì„œ ëª» ë§¤ì¹­í•œ ì¼€ì´ìŠ¤ ìˆ˜:\", not_found_json)\n",
    "\n",
    "    # dfì— text ì»¬ëŸ¼ ì±„ìš°ê¸°\n",
    "    def get_transcript(row):\n",
    "        return utt2text.get(row[\"utt_id\"], \"\")\n",
    "\n",
    "    df = df.copy()\n",
    "    df[\"text\"] = df.apply(get_transcript, axis=1)\n",
    "\n",
    "    no_label_mask = (df[\"text\"].astype(str).str.strip() == \"\")\n",
    "    print(\"âš ï¸ ë¼ë²¨ ëª» ì°¾ì€ ìƒ˜í”Œ ìˆ˜:\", no_label_mask.sum())\n",
    "    print(\"âœ… ë¼ë²¨ ìˆëŠ” ìƒ˜í”Œ ìˆ˜:\", (~no_label_mask).sum())\n",
    "\n",
    "    df_labeled = df[~no_label_mask].reset_index(drop=True)\n",
    "    print(\"âœ… ìµœì¢… ì‚¬ìš© df ìƒ˜í”Œ ìˆ˜:\", len(df_labeled))\n",
    "    if len(df_labeled) > 0:\n",
    "        display(df_labeled.head())\n",
    "    return df_labeled\n",
    "\n",
    "train_df = attach_labels(train_base_df, LABEL_BASE)\n",
    "val_df   = attach_labels(val_base_df,   LABEL_BASE)\n",
    "test_df  = attach_labels(test_base_df,  LABEL_BASE)\n",
    "\n",
    "print(\"\\ntrain_df.shape:\", train_df.shape)\n",
    "print(\"val_df.shape   :\", val_df.shape)\n",
    "print(\"test_df.shape  :\", test_df.shape)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "J4jA0t2JbGRQ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1762794798059,
     "user_tz": -540,
     "elapsed": 557400,
     "user": {
      "displayName": "ì´ì•„í˜„",
      "userId": "10263290526675293811"
     }
    },
    "outputId": "abd90ddb-329f-46f6-fa9a-0b58b7016061"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# ---------------------------------------------------\n",
    "#  ffmpegë¡œ 0.7ë°°ì† ì¦ê°•\n",
    "# ---------------------------------------------------\n",
    "def speed_perturb(in_path: str, out_path: str, factor: float):\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "    cmd = [\n",
    "        \"ffmpeg\", \"-y\",\n",
    "        \"-i\", in_path,\n",
    "        \"-filter:a\", f\"atempo={factor}\",\n",
    "        out_path,\n",
    "    ]\n",
    "    subprocess.run(\n",
    "        cmd,\n",
    "        stdout=subprocess.DEVNULL,\n",
    "        stderr=subprocess.DEVNULL,\n",
    "        check=True,\n",
    "    )\n",
    "\n",
    "FACTOR = 0.7\n",
    "speed_tag = str(FACTOR).replace(\".\", \"_\")   # 0.7 -> \"0_7\"\n",
    "\n",
    "AUG_TRAIN_BASE = os.path.join(ROOT_DIR, \"trainingdata\", f\"Sourcedata_speed{speed_tag}\")\n",
    "print(\"AUG_TRAIN_BASE:\", AUG_TRAIN_BASE)\n",
    "\n",
    "aug_rows = []\n",
    "\n",
    "print(f\"â–¶ 0.7ë°°ì† ì¦ê°• ìƒì„± ì‹œì‘ (ë¼ë²¨ ìˆëŠ” ì›ë³¸ train {len(train_df)}ê°œ ê¸°ì¤€)\")\n",
    "\n",
    "for idx, row in train_df.iterrows():\n",
    "    in_wav = row[\"audio_path\"]\n",
    "\n",
    "    # TRAIN_BASE ê¸°ì¤€ ìƒëŒ€ ê²½ë¡œ\n",
    "    rel_path = os.path.relpath(in_wav, TRAIN_BASE)   # age4/0282/xxx.wav\n",
    "    base, ext = os.path.splitext(rel_path)\n",
    "\n",
    "    out_rel = base + f\"_x{FACTOR}\" + ext             # age4/0282/xxx_x0.7.wav\n",
    "    out_wav = os.path.join(AUG_TRAIN_BASE, out_rel)\n",
    "\n",
    "    if not os.path.exists(out_wav):\n",
    "        speed_perturb(in_wav, out_wav, FACTOR)\n",
    "\n",
    "    aug_rows.append({\n",
    "        \"split\": \"train\",\n",
    "        \"age\": row[\"age\"],\n",
    "        \"speaker_id\": row[\"speaker_id\"],\n",
    "        \"utt_id\": row[\"utt_id\"],\n",
    "        \"audio_path\": out_wav,\n",
    "        \"text\": row[\"text\"],\n",
    "        \"speed\": FACTOR,\n",
    "        \"is_augmented\": True,\n",
    "    })\n",
    "\n",
    "aug_df = pd.DataFrame(aug_rows)\n",
    "print(\"âœ… 0.7ë°°ì† ì¦ê°• train ê°œìˆ˜:\", len(aug_df))\n",
    "if len(aug_df) > 0:\n",
    "    display(aug_df.head())\n",
    "\n",
    "# ì›ë³¸ train + 0.7ë°°ì† ì¦ê°• train í•©ì¹˜ê¸°\n",
    "train_df_full = pd.concat([train_df, aug_df], ignore_index=True)\n",
    "print(\"train_df_full (ì›ë³¸+0.7) ê°œìˆ˜:\", len(train_df_full))\n",
    "display(train_df_full.head())"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ELC3NpkSbp1Y",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1762794824505,
     "user_tz": -540,
     "elapsed": 5247,
     "user": {
      "displayName": "ì´ì•„í˜„",
      "userId": "10263290526675293811"
     }
    },
    "outputId": "db2064bc-9edd-4139-821c-c9496169e5df"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "# ---------------------------------------------------\n",
    "#  train/val/test ë¼ë²¨ë§ ê²°ê³¼ ì ê²€\n",
    "# ---------------------------------------------------\n",
    "print(\">> ë¼ë²¨ë§ëœ ìƒ˜í”Œ ìˆ˜ í™•ì¸\")\n",
    "print(\"  - train_df_full:\", len(train_df_full))\n",
    "print(\"  - val_df       :\", len(val_df))\n",
    "print(\"  - test_df      :\", len(test_df))\n",
    "\n",
    "if len(train_df_full) == 0:\n",
    "    raise ValueError(\"train_df_full ì´ 0ê°œì…ë‹ˆë‹¤. JSON ë§¤ì¹­(attach_labels) ë¶€ë¶„ì„ ë¨¼ì € í™•ì¸í•˜ì„¸ìš”.\")\n",
    "if len(val_df) == 0:\n",
    "    raise ValueError(\"val_df ê°€ 0ê°œì…ë‹ˆë‹¤. val ë¼ë²¨ ë§¤ì¹­ì„ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "if len(test_df) == 0:\n",
    "    raise ValueError(\"test_df ê°€ 0ê°œì…ë‹ˆë‹¤. test ë¼ë²¨ ë§¤ì¹­ì„ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "\n",
    "# ---------------------------------------------------\n",
    "#  Whisper ëª¨ë¸ / Processor ë¡œë“œ\n",
    "# ---------------------------------------------------\n",
    "MODEL_NAME = \"openai/whisper-small\"   # tiny/base ë“±ìœ¼ë¡œ ë°”ê¿”ë„ ë¨\n",
    "\n",
    "processor = WhisperProcessor.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    language=\"Korean\",\n",
    "    task=\"transcribe\",\n",
    ")\n",
    "feature_extractor = processor.feature_extractor\n",
    "tokenizer         = processor.tokenizer\n",
    "\n",
    "model = WhisperForConditionalGeneration.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# í•­ìƒ í•œêµ­ì–´ transcribeë¡œ ê³ ì •\n",
    "model.config.forced_decoder_ids = processor.get_decoder_prompt_ids(\n",
    "    language=\"Korean\",\n",
    "    task=\"transcribe\",\n",
    ")\n",
    "model.config.suppress_tokens = []\n",
    "model.config.use_cache = False\n",
    "\n",
    "print(\"CUDA ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€:\", torch.cuda.is_available())\n",
    "\n",
    "# ---------------------------------------------------\n",
    "#  torchaudioë¡œ ì˜¤ë””ì˜¤ ì½ê¸° (ë¶ˆëŸ‰ íŒŒì¼ì€ ë¬´ìŒìœ¼ë¡œ ëŒ€ì²´)\n",
    "# ---------------------------------------------------\n",
    "import numpy as np\n",
    "\n",
    "def load_audio_16k_mono(path: str):\n",
    "    \"\"\"\n",
    "    - torchaudio.loadë¡œ wav ì½ê¸°\n",
    "    - ì±„ë„ ì—¬ëŸ¬ ê°œë©´ monoë¡œ í‰ê· \n",
    "    - 16kHzë¡œ ë¦¬ìƒ˜í”Œ\n",
    "    - ë¬¸ì œê°€ ìƒê¸°ë©´ 1ì´ˆì§œë¦¬ ë¬´ìŒ ë°˜í™˜ (í•™ìŠµì€ ë˜ê²Œë”)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        waveform, sr = torchaudio.load(path)  # (channels, time)\n",
    "    except Exception as e:\n",
    "        print(\"âš ï¸ ì˜¤ë””ì˜¤ ë¡œë“œ ì‹¤íŒ¨, ë¬´ìŒìœ¼ë¡œ ëŒ€ì²´:\", path, \"ì—ëŸ¬:\", e)\n",
    "        # 1ì´ˆì§œë¦¬ ë¬´ìŒ(16000 ìƒ˜í”Œ)\n",
    "        return np.zeros(16000, dtype=np.float32)\n",
    "\n",
    "    # mono\n",
    "    if waveform.shape[0] > 1:\n",
    "        waveform = waveform.mean(dim=0, keepdim=True)\n",
    "\n",
    "    if sr != 16000:\n",
    "        resampler = torchaudio.transforms.Resample(sr, 16000)\n",
    "        waveform = resampler(waveform)\n",
    "\n",
    "    waveform = waveform.squeeze(0).numpy()\n",
    "    return waveform\n",
    "\n",
    "# ---------------------------------------------------\n",
    "#  pandas â†’ HF Dataset (Audio íƒ€ì… ì“°ì§€ ì•ŠìŒ)\n",
    "# ---------------------------------------------------\n",
    "from datasets import Dataset\n",
    "\n",
    "def make_hf_dataset(df: pd.DataFrame) -> Dataset:\n",
    "    # ì˜¤ë””ì˜¤ íŒŒì¼ì€ ë°”ë¡œ ì•ˆ ì½ê³ , ê²½ë¡œ + í…ìŠ¤íŠ¸ë§Œ Datasetì— ë„£ì–´ë‘”ë‹¤\n",
    "    ds = Dataset.from_pandas(df[[\"audio_path\", \"text\"]].copy())\n",
    "    return ds\n",
    "\n",
    "train_ds = make_hf_dataset(train_df_full)\n",
    "val_ds   = make_hf_dataset(val_df)\n",
    "test_ds  = make_hf_dataset(test_df)\n",
    "\n",
    "print(\">> HF Dataset í¬ê¸°\")\n",
    "print(\"  - train_ds:\", len(train_ds))\n",
    "print(\"  - val_ds  :\", len(val_ds))\n",
    "print(\"  - test_ds :\", len(test_ds))\n",
    "\n",
    "# ì—¬ê¸°ì„œ ë” ì´ìƒ train_ds[0] ê°™ì€ ê±´ ì•ˆ ì°ëŠ”ë‹¤ (ë¹ˆ ê²½ìš° ì—ëŸ¬ ë°©ì§€)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "#  ì „ì²˜ë¦¬ í•¨ìˆ˜: ì—¬ê¸°ì„œ torchaudioë¡œ ì‹¤ì œ ë¡œë“œ\n",
    "# ---------------------------------------------------\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "\n",
    "def load_audio_16k_mono(path: str):\n",
    "    \"\"\"\n",
    "    - torchaudioë¡œ wav ë¡œë“œ\n",
    "    - ì±„ë„ ì—¬ëŸ¬ ê°œë©´ monoë¡œ í‰ê· \n",
    "    - 16kHzë¡œ ë¦¬ìƒ˜í”Œ\n",
    "    - ë¬¸ì œ ìƒê¸°ë©´ 1ì´ˆ ë¬´ìŒ ë°˜í™˜ (í•™ìŠµì€ ê³„ì† ì§„í–‰ë˜ê²Œ)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        waveform, sr = torchaudio.load(path)  # (channels, time)\n",
    "\n",
    "        # mono\n",
    "        if waveform.shape[0] > 1:\n",
    "            waveform = waveform.mean(dim=0, keepdim=True)\n",
    "\n",
    "        if sr != 16000:\n",
    "            resampler = torchaudio.transforms.Resample(sr, 16000)\n",
    "            waveform = resampler(waveform)\n",
    "\n",
    "        return waveform.squeeze(0).numpy()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"âš ï¸ ì˜¤ë””ì˜¤ ë¡œë“œ ì‹¤íŒ¨, ë¬´ìŒìœ¼ë¡œ ëŒ€ì²´:\", path, \"ì—ëŸ¬:\", e)\n",
    "        return np.zeros(16000, dtype=np.float32)  # 1ì´ˆì§œë¦¬ ë¬´ìŒ\n",
    "\n",
    "def prepare_dataset(batch):\n",
    "    paths = batch[\"audio_path\"]           # ì´ì œ ê²½ë¡œë§Œ ë“¤ì–´ ìˆìŒ\n",
    "    audio_arrays = [load_audio_16k_mono(p) for p in paths]\n",
    "\n",
    "    inputs = feature_extractor(\n",
    "        audio_arrays,\n",
    "        sampling_rate=16000,\n",
    "    )\n",
    "    batch[\"input_features\"] = inputs[\"input_features\"]\n",
    "\n",
    "    labels = tokenizer(batch[\"text\"])\n",
    "    batch[\"labels\"] = labels[\"input_ids\"]\n",
    "    return batch\n",
    "\n",
    "train_ds_proc = train_ds.map(\n",
    "    prepare_dataset,\n",
    "    remove_columns=train_ds.column_names,\n",
    "    batched=True,\n",
    "    num_proc=1,\n",
    ")\n",
    "\n",
    "val_ds_proc = val_ds.map(\n",
    "    prepare_dataset,\n",
    "    remove_columns=val_ds.column_names,\n",
    "    batched=True,\n",
    "    num_proc=1,\n",
    ")\n",
    "\n",
    "test_ds_proc = test_ds.map(\n",
    "    prepare_dataset,\n",
    "    remove_columns=test_ds.column_names,\n",
    "    batched=True,\n",
    "    num_proc=1,\n",
    ")\n",
    "\n",
    "print(\">> ì „ì²˜ë¦¬ í›„ Dataset í¬ê¸°\")\n",
    "print(\"  - train_ds_proc:\", len(train_ds_proc))\n",
    "print(\"  - val_ds_proc  :\", len(val_ds_proc))\n",
    "print(\"  - test_ds_proc :\", len(test_ds_proc))\n",
    "\n",
    "# ---------------------------------------------------\n",
    "#  DataCollator + WER/CER metric\n",
    "# ---------------------------------------------------\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "    padding: Union[bool, str] = True\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # 1) ì˜¤ë””ì˜¤ íŠ¹ì§•\n",
    "        input_features = [{\"input_features\": f[\"input_features\"]} for f in features]\n",
    "        # 2) ë¼ë²¨ í† í°\n",
    "        label_features = [{\"input_ids\": f[\"labels\"]} for f in features]\n",
    "\n",
    "        batch = self.processor.feature_extractor.pad(\n",
    "            input_features,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        labels_batch = self.processor.tokenizer.pad(\n",
    "            label_features,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(\n",
    "            labels_batch[\"attention_mask\"].ne(1),\n",
    "            -100,\n",
    "        )\n",
    "        batch[\"labels\"] = labels\n",
    "        return batch\n",
    "\n",
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)\n",
    "\n",
    "wer_metric = evaluate.load(\"wer\")\n",
    "cer_metric = evaluate.load(\"cer\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    pred_ids = eval_pred.predictions\n",
    "    if isinstance(pred_ids, tuple):\n",
    "        pred_ids = pred_ids[0]\n",
    "\n",
    "    label_ids = eval_pred.label_ids\n",
    "    label_ids = np.where(label_ids == -100, tokenizer.pad_token_id, label_ids)\n",
    "\n",
    "    pred_str  = tokenizer.batch_decode(pred_ids,  skip_special_tokens=True)\n",
    "    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    wer = wer_metric.compute(predictions=pred_str, references=label_str)\n",
    "    cer = cer_metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"wer\": wer, \"cer\": cer}"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428,
     "referenced_widgets": [
      "036446d0c09e4c9c96b291bbe0322506",
      "6afe9e36f6004f68b9eb2a4db1e6b2fa",
      "ca881b60d4cf4cfd93e6028de4c61e76",
      "b9829e48be5346858801a3faae8158b3",
      "6e091cd5bb29460c850474d44a5cb39c",
      "a6fd7058a1ea4c268ee28ce53f37f35d",
      "9a8908502e884c2b8112fa353ebacea8",
      "3780484f77b6461987f444caf98bb593",
      "343665541adf43e2b28d4619327c29ca",
      "c9a805b1a43f40bc9d47f91374eb7d61",
      "eb632c9a9fe14ffeb3d712ba22219a46",
      "fe4bf5e9a610480d9bab031fab5ea1f2",
      "85ce0273c19346ec8d54d4bd44a5b9e2",
      "e8fb0ba1f0744bcc95a5739e12d6fa46",
      "422f8c953f1746cc9a3dfa808febc9c2",
      "83fb047bc7d94bcb87b6ebcffe494aad",
      "dd48bb32a4f645daae2575b08b4193ed",
      "788fa91239724efbbe6b87007f5a80bd",
      "b6fa99e2ffa742bcb4466e8d1b7e5481",
      "53d20bcad5f8489e8ad14ccb987d1b0d",
      "40c561442bb7452db6f8eedf58e23872",
      "7e5aa5573c314038ba018d14d12ee135",
      "56918da9de9546ee9b23b7779fd20a06",
      "f705a7005fd74dfbbda9a153530b2853",
      "f96f7050775d4514a05c2978645b90a8",
      "ddd7df28a37241d491cc47adc727d58a",
      "11b74d334aaa4f2ea8f91fc6e13bde49",
      "88f77018606f455d9eca1823e747ce1b",
      "a2315bb771704511884d430e0fe725ed",
      "bf6fd0a1c4d04ee3a894460e4f4cfb04",
      "e0006d5ff864422eaab5b6143b8ea61a",
      "a8c09eed8a214e1cb5fae7276f2f34e4",
      "b8926abb77044313826155d85f4d8970"
     ]
    },
    "id": "-vPaoKMidPmf",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1762796562575,
     "user_tz": -540,
     "elapsed": 33014,
     "user": {
      "displayName": "ì´ì•„í˜„",
      "userId": "10263290526675293811"
     }
    },
    "outputId": "03e91aeb-a260-4bf8-8b03-470f58b7db99"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer"
   ],
   "metadata": {
    "id": "XqzB4N-m0R5t",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1762796569327,
     "user_tz": -540,
     "elapsed": 6,
     "user": {
      "displayName": "ì´ì•„í˜„",
      "userId": "10263290526675293811"
     }
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "output_dir = \"/content/whisper_children_0_7\"\n",
    "\n",
    "fp16 = torch.cuda.is_available()\n",
    "\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    num_train_epochs=5,\n",
    "    learning_rate=1e-5,\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"wer\",\n",
    "    greater_is_better=False,\n",
    "    predict_with_generate=True,   # âœ… Seq2SeqTrainingArgumentsë¼ì„œ ì´ì œ ì •ìƒ\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    remove_unused_columns=False,\n",
    "    generation_max_length=128,       # (ì„ íƒ) ë””ì½”ë”© ê¸¸ì´\n",
    "    generation_num_beams=1,          # (ì„ íƒ) beam search ì•ˆ ì“°ë©´ 1\n",
    ")\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_ds_proc,   # ë„¤ê°€ ì“°ëŠ” train_ds_proc / train_proc_full ë“±\n",
    "    eval_dataset=val_ds_proc,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=processor.feature_extractor,  # í˜¹ì€ tokenizer/processor\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "print(\"â–¶ 0.7ë°°ì† êµ¬ì„± (train=ì›ë³¸+0.7, val/test=ì›ë³¸) í•™ìŠµ ì‹œì‘\")\n",
    "train_result = trainer.train()\n",
    "\n",
    "# ëª¨ë¸ ì €ì¥ (ì˜µì…˜)\n",
    "trainer.save_model(os.path.join(output_dir, \"final_model\"))\n",
    "processor.save_pretrained(os.path.join(output_dir, \"final_processor\"))\n",
    "\n",
    "# ---------------------------------------------------\n",
    "#  Validation í‰ê°€\n",
    "# ---------------------------------------------------\n",
    "eval_metrics = trainer.evaluate()\n",
    "print(\"\\nâœ… Validation ê²°ê³¼ (0.7ë°°ì† êµ¬ì„±):\")\n",
    "print(f\"WER: {eval_metrics['eval_wer']:.4f}\")\n",
    "print(f\"CER: {eval_metrics['eval_cer']:.4f}\")\n",
    "\n",
    "# ---------------------------------------------------\n",
    "#  Test set í‰ê°€ + ì „ì²´ ë¬¸ì¥ ë¹„êµ + CSV ì €ì¥\n",
    "# ---------------------------------------------------\n",
    "print(\"\\nâ–¶ Test set í‰ê°€ ì¤‘...\")\n",
    "\n",
    "test_outputs = trainer.predict(test_ds_proc)\n",
    "pred_ids = test_outputs.predictions\n",
    "if isinstance(pred_ids, tuple):\n",
    "    pred_ids = pred_ids[0]\n",
    "\n",
    "label_ids = test_outputs.label_ids\n",
    "label_ids = np.where(label_ids == -100, tokenizer.pad_token_id, label_ids)\n",
    "\n",
    "pred_str  = tokenizer.batch_decode(pred_ids,  skip_special_tokens=True)\n",
    "label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "test_wer = wer_metric.compute(predictions=pred_str, references=label_str)\n",
    "test_cer = cer_metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "print(\"\\nâœ… Test ê²°ê³¼ (0.7ë°°ì† êµ¬ì„±, train=ì›ë³¸+0.7 / val,test=ì›ë³¸):\")\n",
    "print(f\"Test WER: {test_wer:.4f}\")\n",
    "print(f\"Test CER: {test_cer:.4f}\")\n",
    "\n",
    "# ğŸ”¹ Test ì „ì²´ refâ€“pred ì¶œë ¥\n",
    "print(\"\\nğŸ§© Test ì „ì²´ ìƒ˜í”Œ REF vs PRED\\n\" + \"-\"*60)\n",
    "for i in range(len(pred_str)):\n",
    "    print(f\"\\nğŸ”¹ ìƒ˜í”Œ {i+1}\")\n",
    "    print(f\"[REF] {label_str[i]}\")\n",
    "    print(f\"[PRED] {pred_str[i]}\")\n",
    "\n",
    "# ğŸ”¹ CSVë¡œ ì €ì¥\n",
    "compare_df = pd.DataFrame({\n",
    "    \"ref\": label_str,\n",
    "    \"pred\": pred_str,\n",
    "})\n",
    "csv_path = os.path.join(output_dir, \"predictions_compare0.7(1).csv\")\n",
    "compare_df.to_csv(csv_path, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"\\nâœ… ì „ì²´ refâ€“pred ë¹„êµ CSV ì €ì¥ ì™„ë£Œ: {csv_path}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "xo__yysNdRwa",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1762797882014,
     "user_tz": -540,
     "elapsed": 1309971,
     "user": {
      "displayName": "ì´ì•„í˜„",
      "userId": "10263290526675293811"
     }
    },
    "outputId": "e65543af-a369-4254-e1b9-f5d0d4fc7a3f"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(len(train_ds_proc))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a5PvJlBk8aID",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1762797924886,
     "user_tz": -540,
     "elapsed": 7,
     "user": {
      "displayName": "ì´ì•„í˜„",
      "userId": "10263290526675293811"
     }
    },
    "outputId": "7fea3e20-d949-4e60-ad75-1b24bebcc4bd"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
